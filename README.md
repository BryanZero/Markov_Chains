# Markov_Chains

Enter an absorbing Markov chain into solution(m) and you will get the probability states

*This code was made for personal use and may not have adequate notes, use at own discretion.*
